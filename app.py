import streamlit as st
import cv2
import numpy as np
import pandas as pd
from scipy.io import wavfile
import io
import base64

# --- 1. ì†Œë¦¬ ìƒì„± í•¨ìˆ˜ (ìˆ˜í•™ì  ì—°ì‚°) ---
def generate_tone(frequency, duration, volume=0.5, sample_rate=44100):
    t = np.linspace(0, duration, int(sample_rate * duration))
    # ì‚¬ì¸íŒŒ ìƒì„± (ë¹›ì˜ ì²­ê°í™”)
    tone = volume * np.sin(2 * np.pi * frequency * t)
    return tone

# --- 2. í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(layout="wide", page_title="Light Orchestrator")
st.title("ğŸšŒ Night Bus Light-to-Music")

# --- 3. ì‚¬ì´ë“œë°” (ì •ë³´ì°½ ëŒ€ì²´) ---
with st.sidebar:
    st.header("ğŸ“Š Video Info")
    uploaded_file = st.file_uploader("ì˜ìƒì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=['mp4', 'mov', 'avi'])
    st.info("ê´‘ì› ìœ„ì¹˜ê°€ ë†’ì„ìˆ˜ë¡ ê³ ìŒ, ë‚®ì„ìˆ˜ë¡ ì €ìŒì´ ìƒì„±ë©ë‹ˆë‹¤.")

# --- 4. ë©”ì¸ í™”ë©´ (3ê°œ êµ¬ì—­) ---
col_vid, col_snd = st.columns([1, 1])

if uploaded_file:
    # ì„ì‹œ íŒŒì¼ë¡œ ì˜ìƒ ì½ê¸°
    g = io.BytesIO(uploaded_file.read())
    with open("temp_video.mp4", "wb") as f:
        f.write(g.read())
    
    cap = cv2.VideoCapture("temp_video.mp4")
    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    # ì •ë³´ì°½ ì—…ë°ì´íŠ¸
    with st.sidebar:
        st.write(f"FPS: {fps}")
        st.write(f"Total Frames: {total_frames}")

    # ì†Œë¦¬ ë°ì´í„° ì €ì¥ì„ ìœ„í•œ ë”•ì…”ë„ˆë¦¬
    # ë ˆì´ì–´: Small(ê³ ìŒ), Medium(ì¤‘ìŒ), Large(ì €ìŒ)
    audio_layers = {"Small": [], "Medium": [], "Large": []}
    
    # ë¶„ì„ í”„ë¡œì„¸ìŠ¤ (ìƒ˜í”Œë§: 10í”„ë ˆì„ë‹¹ 1ë°•ì)
    progress_bar = st.progress(0)
    step = 10 
    
    for i in range(0, total_frames, step):
        cap.set(cv2.CAP_PROP_POS_FRAMES, i)
        ret, frame = cap.read()
        if not ret: break
        
        # ê´‘ì› ì¶”ì¶œ ë¡œì§
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        _, thresh = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY) # ë°ì€ ë¶€ë¶„ë§Œ ë‚¨ê¸°ê¸°
        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        for cnt in contours:
            area = cv2.contourArea(cnt)
            if area < 5: continue # ë„ˆë¬´ ì‘ì€ ë…¸ì´ì¦ˆ ì œê±°
            
            # ì¤‘ì‹¬ì  ì°¾ê¸°
            M = cv2.moments(cnt)
            if M["m00"] == 0: continue
            cy = int(M["m01"] / M["m00"])
            
            # ë†’ì´(cy)ë¥¼ ì£¼íŒŒìˆ˜ë¡œ ë³€í™˜ (ìœ„ìª½ì´ ê³ ìŒ)
            freq = 1000 - (cy * 1.5) # ê°„ë‹¨í•œ ë§¤í•‘ ê³µì‹
            duration = (1/fps) * step
            
            tone = generate_tone(freq, duration, volume=min(area/1000, 1.0))
            
            # í¬ê¸°ì— ë”°ë¼ ë ˆì´ì–´ ë¶„ë¥˜
            if area < 50: audio_layers["Small"].append(tone)
            elif area < 200: audio_layers["Medium"].append(tone)
            else: audio_layers["Large"].append(tone)
        
        progress_bar.progress(i / total_frames)

    # 1ë²ˆ ì°½: ì˜ìƒ ì¬ìƒ
    with col_vid:
        st.header("ğŸ“½ Video View")
        st.video(uploaded_file)

    # 2ë²ˆ ì°½: ì†Œë¦¬ ë ˆì´ì–´ ë° ë‹¤ìš´ë¡œë“œ
    with col_snd:
        st.header("ğŸµ Sound Layers")
        
        final_audio_all = []
        for name, tones in audio_layers.items():
            if tones:
                layer_data = np.concatenate(tones)
                st.subheader(f"Layer: {name}")
                st.audio(layer_data, sample_rate=44100)
                
                # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ìƒì„± (WAV ë³€í™˜)
                buffer = io.BytesIO()
                wavfile.write(buffer, 44100, (layer_data * 32767).astype(np.int16))
                st.download_button(f"Download {name} Layer", buffer, f"{name}.wav")
                final_audio_all.append(layer_data)

        if final_audio_all:
            st.divider()
            st.button("ğŸ”¥ Download All Layers (Mix)")

    cap.release()
