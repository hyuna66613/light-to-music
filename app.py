import streamlit as st
import cv2
import numpy as np
from scipy.io import wavfile
import io
import plotly.graph_objects as go
from pydub import AudioSegment # MP3 ë³€í™˜ìš©

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(layout="wide", page_title="GarageLight DAW")
st.title("ğŸ¹ GarageLight: Optical Digital Audio Workstation")

# --- 1. ì‚¬ì´ë“œë°” ì •ë³´ì°½ ---
with st.sidebar:
    st.header("ğŸ› Control Panel")
    uploaded_file = st.file_uploader("ì˜ìƒì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=['mp4', 'mov', 'avi'])
    st.info("ê°œë³„ ê´‘ì›ì„ íŠ¸ë˜í‚¹í•˜ì—¬ ë…ë¦½ì ì¸ ì‹ ì‹œì‚¬ì´ì € íŠ¸ë™ì„ ìƒì„±í•©ë‹ˆë‹¤.")

if uploaded_file:
    try:
        # ì˜ìƒ ì²˜ë¦¬ ì„¤ì • (Full Frame ëª¨ë“œ)
        with open("temp_video.mp4", "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        cap = cv2.VideoCapture("temp_video.mp4")
        fps = cap.get(cv2.CAP_PROP_FPS) or 30
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        
        sample_rate = 44100
        # ìµœëŒ€ 10ê°œì˜ ë…ë¦½ ê´‘ì› íŠ¸ë™ ìƒì„± (ì„œë²„ ë¶€í•˜ ë°©ì§€)
        max_tracks = 10
        tracks_audio = [[] for _ in range(max_tracks)]
        tracks_visual = [[] for _ in range(max_tracks)]
        
        st.write(f"ğŸš€ {total_frames}í”„ë ˆì„ ì „ì²´ ë¶„ì„ ì¤‘... (ì „ììŒì•… ëª¨ë“œ)")
        prog = st.progress(0)

        for i in range(total_frames):
            ret, frame = cap.read()
            if not ret: break
            
            # ê´‘ì› ë¶„ì„
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            _, thresh = cv2.threshold(gray, 230, 255, cv2.THRESH_BINARY)
            contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            # í•œ í”„ë ˆì„ì˜ ì§€ì† ì‹œê°„
            duration = 1.0 / fps
            t = np.linspace(0, duration, int(sample_rate * duration), False)
            
            # ìƒìœ„ 10ê°œ ê´‘ì›ë§Œ íŠ¸ë˜í‚¹
            sorted_contours = sorted(contours, key=cv2.contourArea, reverse=True)[:max_tracks]
            
            for idx, cnt in enumerate(sorted_contours):
                area = cv2.contourArea(cnt)
                M = cv2.moments(cnt)
                if M["m00"] == 0: continue
                cx, cy = int(M["m10"] / M["m00"]), int(M["m01"] / M["m00"])
                
                # ìƒ‰ìƒ ì¶”ì¶œ (B, G, R)
                b, g, r = frame[cy, cx]
                
                # ë§¤í•‘ ê³µì‹ (ìœ„ì¹˜->ìŒì •, ìƒ‰ìƒ->ìŒìƒ‰, ë°ê¸°->ë³¼ë¥¨)
                base_freq = 200 + ( (height - cy) * 2 ) # ë†’ì„ìˆ˜ë¡ ê³ ìŒ
                # ìƒ‰ìƒì— ë”°ë¥¸ ë°°ìŒ ì¶”ê°€ (ì „ììŒ íš¨ê³¼)
                freq = base_freq + (r * 0.5)
                vol = min((area / 1000) * (np.mean([r, g, b]) / 255), 1.0)
                
                # ì‚¬ê°íŒŒ(Square Wave) ìƒì„± - ë” ì „ììŒì•…ìŠ¤ëŸ¬ìš´ ì†Œë¦¬
                tone = vol * np.sign(np.sin(2 * np.pi * freq * t))
                
                tracks_audio[idx].append(tone)
                tracks_visual[idx].append(vol)
            
            # ê´‘ì›ì´ ì—†ëŠ” íŠ¸ë™ì€ ì¹¨ë¬µ ì²˜ë¦¬
            for j in range(len(sorted_contours), max_tracks):
                tracks_audio[j].append(np.zeros_like(t))
                tracks_visual[j].append(0)
                
            if i % 10 == 0: prog.progress(i / total_frames)

        # UI ë°°ì¹˜ (ì˜ìƒ ì°½ / DAW íƒ€ì„ë¼ì¸ ì°½)
        col_vid, col_daw = st.columns([1, 2])
        
        with col_vid:
            st.header("ğŸ“½ Input Source")
            st.video(uploaded_file)
            st.metric("Resolution", f"{width}x{height}")
            st.metric("Frame Count", total_frames)

        with col_daw:
            st.header("ğŸ¹ GarageLight DAW Timeline")
            
            for idx in range(max_tracks):
                if any(tracks_visual[idx]):
                    with st.container():
                        st.markdown(f"**Track {idx+1}: Optical Oscillator**")
                        # íƒ€ì„ë¼ì¸ íŒŒí˜• ì‹œê°í™”
                        fig = go.Figure()
                        fig.add_trace(go.Scatter(y=tracks_visual[idx], fill='tozeroy', line_color='#007AFF')) # ê°œëŸ¬ì§€ë°´ë“œ ë¸”ë£¨
                        fig.update_layout(height=80, margin=dict(l=0, r=0, t=0, b=0), xaxis_visible=False, yaxis_visible=False, paper_bgcolor="rgba(0,0,0,0)", plot_bgcolor="rgba(0,0,0,0)")
                        st.plotly_chart(fig, use_container_width=True, config={'displayModeBar': False})
                        
                        # ì˜¤ë””ì˜¤ ë° MP3 ë‹¤ìš´ë¡œë“œ
                        full_audio = np.concatenate(tracks_audio[idx])
                        c1, c2 = st.columns([4, 1])
                        with c1:
                            st.audio(full_audio, sample_rate=sample_rate)
                        with c2:
                            # MP3 ë³€í™˜
                            buf = io.BytesIO()
                            wavfile.write(buf, sample_rate, (full_audio * 32767).astype(np.int16))
                            audio_seg = AudioSegment.from_wav(io.BytesIO(buf.getvalue()))
                            mp3_buf = io.BytesIO()
                            audio_seg.export(mp3_buf, format="mp3")
                            st.download_button("MP3", mp3_buf.getvalue(), f"track_{idx+1}.mp3")

    except Exception as e:
        st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}. 'pydub' ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ 'ffmpeg'ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
