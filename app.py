import streamlit as st
import cv2
import numpy as np
import io
import wave
import plotly.graph_objects as go

st.set_page_config(layout="wide", page_title="Luxury Optical Synth")
st.title("ğŸ¹ Luxury Electronica: Optical Sound Design")

# --- ê³ ê¸‰ ì‚¬ìš´ë“œ ë° ë¦¬ë²„ë¸Œ ì—”ì§„ ---
def apply_reverb_style(tone, sample_rate, decay=0.4):
    """ì†Œë¦¬ë¥¼ ê°ì‹¸ì£¼ëŠ” ë“¯í•œ ì”í–¥(Reverb) íš¨ê³¼ ì‹œë®¬ë ˆì´ì…˜"""
    n = len(tone)
    env = np.ones(n)
    # ëë¶€ë¶„ì„ ì•„ì£¼ ë¶€ë“œëŸ½ê²Œ ê°ì‡ ì‹œì¼œ ê³µê°„ê° í˜•ì„±
    env = np.exp(-np.linspace(0, 1/decay, n))
    return tone * env

def generate_luxury_sound(t, freq, layer_idx, sample_rate):
    """
    Layer 0: Deep & Warm Bass (ê°ì‹¸ì£¼ëŠ” ì €ìŒ)
    Layer 1: Analog Pluck (ë”°ëœ»í•œ ë¦¬ë“¬)
    Layer 2: Soft Poly Lead (ë¶€ë“œëŸ¬ìš´ ë©œë¡œë””)
    Layer 3: Crystal Bell (ê³ ê¸‰ìŠ¤ëŸ¬ìš´ ê³ ìŒ ìš¸ë¦¼)
    """
    if layer_idx == 0:  # ğŸŒŠ Deep & Warm Bass
        # ì €ìŒ ì£¼íŒŒìˆ˜ ê³ ì • ë° ì‚¬ì¸íŒŒ ìœ„ì£¼ë¡œ êµ¬ì„± (ê°ì‹¸ì£¼ëŠ” ëŠë‚Œ)
        base_f = 50 + (freq % 40)
        wave_data = np.sin(2 * np.pi * base_f * t) + 0.2 * np.sin(2 * np.pi * base_f * 2 * t)
        return apply_reverb_style(wave_data, sample_rate, decay=2.0)

    elif layer_idx == 1:  # ğŸ¹ Warm Pluck
        wave_data = 0.8 * np.sin(2 * np.pi * freq * t) + 0.2 * np.sign(np.sin(2 * np.pi * freq * t))
        return apply_reverb_style(wave_data, sample_rate, decay=0.2)

    elif layer_idx == 2:  # ğŸ¤ Soft Lead
        wave_data = np.sin(2 * np.pi * freq * t) * (1 + 0.2 * np.sin(2 * np.pi * 5 * t)) # ë¹„ë¸Œë¼í†  ì¶”ê°€
        return apply_reverb_style(wave_data, sample_rate, decay=0.8)

    else:  # ğŸ”” Crystal Bell (ê³ ê¸‰ìŠ¤ëŸ¬ìš´ ê³ ìŒ)
        # ë‚ ì¹´ë¡œìš´ ì†Œë¦¬ë¥¼ ì—†ì• ê¸° ìœ„í•´ ì—¬ëŸ¬ ì‚¬ì¸íŒŒë¥¼ ì¤‘ì²© (FM í•©ì„± ëŠë‚Œ)
        wave_data = (np.sin(2 * np.pi * freq * t) * 0.6 + 
                     np.sin(2 * np.pi * freq * 2.01 * t) * 0.3 + 
                     np.sin(2 * np.pi * freq * 3.02 * t) * 0.1)
        # ì§§ì§€ë§Œ ëì´ ë¶€ë“œëŸ¬ìš´ ì—”ë²¨ë¡œí”„
        env = np.exp(-np.linspace(0, 12, len(t)))
        return (wave_data * env).astype(np.float32)

with st.sidebar:
    st.header("ğŸ› Studio Mixer")
    uploaded_file = st.file_uploader("ì˜ìƒì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=['mp4', 'mov', 'avi'])
    st.divider()
    active_layers = st.multiselect(
        "ğŸ”Š ë ˆì´ì–´ ë¯¹ì‹± ì„ íƒ",
        ["Layer 1 (Deep Bass)", "Layer 2 (Warm Pluck)", "Layer 3 (Soft Lead)", "Layer 4 (Crystal Bell)"],
        default=["Layer 1 (Deep Bass)", "Layer 2 (Warm Pluck)", "Layer 3 (Soft Lead)", "Layer 4 (Crystal Bell)"]
    )
    intensity_threshold = st.slider("ê´‘ì› ê°ë„", 30, 255, 180)
    master_gain = st.slider("Master Output", 0.5, 5.0, 2.0)

if uploaded_file:
    try:
        with open("temp_video.mp4", "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        cap = cv2.VideoCapture("temp_video.mp4")
        fps = cap.get(cv2.CAP_PROP_FPS) or 30
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        sample_rate = 22050 
        duration = total_frames / fps
        
        tracks_l = [np.zeros(int(sample_rate * duration) + sample_rate) for _ in range(4)]
        tracks_r = [np.zeros(int(sample_rate * duration) + sample_rate) for _ in range(4)]
        vis_data = [[] for _ in range(4)]
        
        prog = st.progress(0)
        for i in range(total_frames):
            ret, frame = cap.read()
            if not ret: break
            
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            _, thresh = cv2.threshold(gray, intensity_threshold, 255, cv2.THRESH_BINARY)
            contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            start_idx = int(i * (sample_rate / fps))
            t = np.linspace(0, 1/fps, int(sample_rate/fps), False).astype(np.float32)
            sorted_cnts = sorted(contours, key=cv2.contourArea, reverse=True)[:4]
            
            for idx, cnt in enumerate(sorted_cnts):
                area = cv2.contourArea(cnt)
                M = cv2.moments(cnt)
                if M["m00"] == 0: continue
                cx = int(M["m10"]/M["m00"])
                
                # ì£¼íŒŒìˆ˜ ë§¤í•‘
                base_f = [55, 220, 440, 880][idx]
                freq = base_f + (area % 100)
                
                tone = generate_luxury_sound(t, freq, idx, sample_rate)
                
                pan_r = np.clip(cx / frame.shape[1], 0.1, 0.9)
                pan_l = 1.0 - pan_r
                
                end_idx = start_idx + len(tone)
                if end_idx < len(tracks_l[0]):
                    tracks_l[idx][start_idx:end_idx] += tone * pan_l * master_gain
                    tracks_r[idx][start_idx:end_idx] += tone * pan_r * master_gain
                vis_data[idx].append(freq)

            for j in range(len(sorted_cnts), 4): vis_data[j].append(None)
            if i % 30 == 0: prog.progress(i / total_frames)

        # ë¯¹ì‹± ì²˜ë¦¬
        final_l, final_r = np.zeros_like(tracks_l[0]), np.zeros_like(tracks_r[0])
        for idx, name in enumerate(["Layer 1 (Deep Bass)", "Layer 2 (Warm Pluck)", "Layer 3 (Soft Lead)", "Layer 4 (Crystal Bell)"]):
            if name in active_layers:
                final_l += tracks_l[idx]
                final_r += tracks_r[idx]

        master_stereo = np.vstack((final_l, final_r)).T
        peak = np.max(np.abs(master_stereo))
        if peak > 0: master_stereo = (master_stereo / peak) * 0.85
        audio_int16 = (master_stereo * 32767).astype(np.int16)

        wav_buf = io.BytesIO()
        with wave.open(wav_buf, 'wb') as wf:
            wf.setnchannels(2); wf.setsampwidth(2); wf.setframerate(sample_rate); wf.writeframes(audio_int16.tobytes())

        # --- UI ë ˆì´ì•„ì›ƒ ---
        st.header("ğŸ Sync Performance & Visualizer")
        col_vid, col_graph = st.columns([1, 1])
        
        with col_vid:
            st.video(uploaded_file)
            st.write("ğŸ”Š **Master Mix**")
            st.audio(wav_buf.getvalue())
            st.download_button("ğŸ’¾ ì „ì²´ ë¯¹ìŠ¤ ë‹¤ìš´ë¡œë“œ", wav_buf.getvalue(), "full_master_mix.wav")

        with col_graph:
            # ê·¸ë˜í”„ ë³µêµ¬
            time_axis = np.linspace(0, duration, total_frames)
            fig = go.Figure()
            colors = ['#00d1ff', '#ff4b4b', '#7752fe', '#ffd700']
            for i in range(4):
                if any(f"Layer {i+1}" in n for n in active_layers):
                    fig.add_trace(go.Scatter(x=time_axis, y=vis_data[i], name=f"Layer {i+1}", line=dict(color=colors[i])))
            fig.update_layout(template="plotly_dark", height=420, margin=dict(l=10, r=10, t=10, b=10), xaxis=dict(rangeslider=dict(visible=True)))
            st.plotly_chart(fig, use_container_width=True)

        # --- ë¶€ë¶„ ì¬ìƒ ë° ë ˆì´ì–´ë³„ ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥ ---
        st.divider()
        st.subheader("ğŸ“ Individual Layer Tracks (Stem Export)")
        export_cols = st.columns(4)
        for i in range(4):
            with export_cols[i]:
                layer_name = ["Deep Bass", "Warm Pluck", "Soft Lead", "Crystal Bell"][i]
                t_buf = io.BytesIO()
                t_data = np.vstack((tracks_l[i], tracks_r[i])).T
                t_peak = np.max(np.abs(t_data))
                if t_peak > 0: t_data = (t_data / t_peak) * 0.8
                t_int16 = (t_data * 32767).astype(np.int16)
                with wave.open(t_buf, 'wb') as wf:
                    wf.setnchannels(2); wf.setsampwidth(2); wf.setframerate(sample_rate); wf.writeframes(t_int16.tobytes())
                
                st.write(f"**Track {i+1}**")
                st.caption(layer_name)
                st.audio(t_buf.getvalue()) # ë¶€ë¶„ ì¬ìƒ ê¸°ëŠ¥
                st.download_button(f"ğŸ“¥ {layer_name} ì €ì¥", t_buf.getvalue(), f"track_{i+1}_{layer_name}.wav")

    except Exception as e:
        st.error(f"ì˜¤ë¥˜: {e}")
