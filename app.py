import streamlit as st
import cv2
import numpy as np
import io
import wave
import plotly.graph_objects as go

st.set_page_config(layout="wide", page_title="Optical Layer DAW")
st.title("ğŸ› Layer-Specific Optical DAW: Contrast Mode")

# --- ë ˆì´ì–´ë³„ ê³ ìœ  ì‚¬ìš´ë“œ ì—”ì§„ ---
def generate_layer_sound(t, freq, area, intensity, layer_idx, sample_rate):
    """
    Layer 1 (ê°€ì¥ í° ë¹›): ì›…ì¥í•œ ìš¸ë¦¼ (Ambient Pad) - ì§€ì†ì„± ê¸¸ê³  ë¶€ë“œëŸ¬ì›€
    Layer 2 (ë‘ ë²ˆì§¸): ë”±ë”± ëŠê¸°ëŠ” ë¹„íŠ¸ (Percussive) - ë§¤ìš° ì§§ê³  íƒ€ê²©ê° ìˆìŒ
    Layer 3 (ì„¸ ë²ˆì§¸): ì¼ë ‰íŠ¸ë¡œ ë¦¬ë“œ (Acid Lead) - ë‚ ì¹´ë¡­ê³  ë³€ì¡°ê°€ ì‹¬í•¨
    Layer 4 (ë„¤ ë²ˆì§¸): í•˜ì´íŒŒì´ ì‹ ìŠ¤ (Chirp) - ë§¤ìš° ë†’ê³  í†¡í†¡ íŠ€ëŠ” ì†Œë¦¬
    """
    if layer_idx == 0:  # ğŸŒŠ Layer 1: ì›…ì¥í•œ ìš¸ë¦¼
        wave = np.sin(2 * np.pi * freq * t)
        # ë§¤ìš° ê¸´ í˜ì´ë“œ ì•„ì›ƒ
        env = np.linspace(1, 0.3, len(t))
        return (wave * env).astype(np.float32)

    elif layer_idx == 1:  # ğŸ¥ Layer 2: ë”±ë”± ëŠê¸°ëŠ” ë¹„íŠ¸
        # ì‚¬ê°íŒŒë¥¼ ì‚¬ìš©í•˜ì—¬ íƒ€ê²©ê° ë¶€ì—¬
        wave = np.sign(np.sin(2 * np.pi * freq * t))
        # ì•„ì£¼ ì§§ì€ ì—”ë²¨ë¡œí”„ (Pluck ì†Œë¦¬)
        env = np.exp(-np.linspace(0, 10, len(t))) 
        return (wave * env * 0.6).astype(np.float32)

    elif layer_idx == 2:  # ğŸ¸ Layer 3: ë‚ ì¹´ë¡œìš´ ë¦¬ë“œ
        # í†±ë‹ˆíŒŒ + í•„í„° ë³€ì¡°
        wave = 2 * (t * freq - np.floor(0.5 + t * freq))
        env = np.ones(len(t))
        env[-int(len(t)*0.5):] = np.linspace(1, 0, int(len(t)*0.5))
        return (wave * env * 0.5).astype(np.float32)

    else:  # âœ¨ Layer 4: ê³ ìŒ Chirp
        wave = np.sin(2 * np.pi * freq * 2 * t) # ì£¼íŒŒìˆ˜ 2ë°°
        # 0.05ì´ˆë§Œ ì†Œë¦¬ ë‚˜ê³  ëŠê¹€
        env = np.zeros(len(t))
        env[:int(len(t)*0.3)] = 1
        return (wave * env * 0.4).astype(np.float32)

with st.sidebar:
    st.header("ğŸ› Layer Mixer")
    uploaded_file = st.file_uploader("ì˜ìƒì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=['mp4', 'mov', 'avi'])
    st.divider()
    # ê°œë³„ ë ˆì´ì–´ í™œì„±í™”/ë¹„í™œì„±í™”
    active_layers = st.multiselect(
        "ğŸ”Š í”Œë ˆì´í•  ë ˆì´ì–´ ì„ íƒ",
        ["Layer 1 (ì›…ì¥í•œ ìš¸ë¦¼)", "Layer 2 (ë”±ë”±í•œ ë¹„íŠ¸)", "Layer 3 (ë‚ ì¹´ë¡œìš´ ë¦¬ë“œ)", "Layer 4 (ê³ ìŒ Chirp)"],
        default=["Layer 1 (ì›…ì¥í•œ ìš¸ë¦¼)", "Layer 2 (ë”±ë”±í•œ ë¹„íŠ¸)", "Layer 3 (ë‚ ì¹´ë¡œìš´ ë¦¬ë“œ)", "Layer 4 (ê³ ìŒ Chirp)"]
    )
    intensity_threshold = st.slider("ë¹› ê°ì§€ ë¬¸í„±ê°’", 50, 255, 200)
    master_gain = st.slider("Master Gain", 0.1, 3.0, 1.5)

if uploaded_file:
    try:
        with open("temp_video.mp4", "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        cap = cv2.VideoCapture("temp_video.mp4")
        fps = cap.get(cv2.CAP_PROP_FPS) or 30
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        sample_rate = 22050 
        duration = total_frames / fps
        
        tracks_l = [np.zeros(int(sample_rate * duration) + sample_rate) for _ in range(4)]
        tracks_r = [np.zeros(int(sample_rate * duration) + sample_rate) for _ in range(4)]
        vis_pitch = [[] for _ in range(4)]
        
        prog = st.progress(0)
        for i in range(total_frames):
            ret, frame = cap.read()
            if not ret: break
            
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            _, thresh = cv2.threshold(gray, intensity_threshold, 255, cv2.THRESH_BINARY)
            contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            start_idx = int(i * (sample_rate / fps))
            t = np.linspace(0, 1/fps, int(sample_rate/fps), False).astype(np.float32)
            
            # ë©´ì  ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ê° ë ˆì´ì–´ì— ë°°ë¶„
            sorted_cnts = sorted(contours, key=cv2.contourArea, reverse=True)[:4]
            
            for idx, cnt in enumerate(sorted_cnts):
                area = cv2.contourArea(cnt)
                M = cv2.moments(cnt)
                if M["m00"] == 0: continue
                cx = int(M["m10"]/M["m00"])
                
                # ë¹›ì˜ íŠ¹ì„±ì— ë”°ë¥¸ ì£¼íŒŒìˆ˜ (ë©´ì  -> ì €ìŒ, ì†Œí˜• -> ê³ ìŒ)
                freq = 80 + (idx * 150) + (1000 / (np.sqrt(area) + 1))
                
                # ë ˆì´ì–´ë³„ íŠ¹í™” ì‚¬ìš´ë“œ ìƒì„±
                tone = generate_layer_sound(t, freq, area, 255, idx, sample_rate)
                
                pan_r = cx / frame.shape[1]
                pan_l = 1.0 - pan_r
                
                end_idx = start_idx + len(tone)
                if end_idx < len(tracks_l[0]):
                    tracks_l[idx][start_idx:end_idx] += tone * pan_l * master_gain
                    tracks_r[idx][start_idx:end_idx] += tone * pan_r * master_gain
                vis_pitch[idx].append(freq)

            for j in range(len(sorted_cnts), 4): vis_pitch[j].append(None)
            if i % 30 == 0: prog.progress(i / total_frames)

        # --- [ì‹¤ì‹œê°„ ë¯¹ì‹±] ---
        master_l = np.zeros_like(tracks_l[0])
        master_r = np.zeros_like(tracks_r[0])
        for idx, name in enumerate(["Layer 1 (ì›…ì¥í•œ ìš¸ë¦¼)", "Layer 2 (ë”±ë”±í•œ ë¹„íŠ¸)", "Layer 3 (ë‚ ì¹´ë¡œìš´ ë¦¬ë“œ)", "Layer 4 (ê³ ìŒ Chirp)"]):
            if name in active_layers:
                master_l += tracks_l[idx]
                master_r += tracks_r[idx]

        master_stereo = np.vstack((master_l, master_r)).T
        peak = np.max(np.abs(master_stereo))
        if peak > 0: master_stereo = (master_stereo / peak) * 0.9
        audio_int16 = (master_stereo * 32767).astype(np.int16)

        wav_buf = io.BytesIO()
        with wave.open(wav_buf, 'wb') as wf:
            wf.setnchannels(2); wf.setsampwidth(2); wf.setframerate(sample_rate); wf.writeframes(audio_int16.tobytes())

        # UI ì¶œë ¥
        col_main, col_sub = st.columns([1.5, 1])
        with col_main:
            st.header("ğŸ Sync Performance")
            st.video(uploaded_file)
            st.audio(wav_buf.getvalue())
            st.download_button("ğŸ’¾ ì „ì²´ ë¯¹ìŠ¤ ë‹¤ìš´ë¡œë“œ", wav_buf.getvalue(), "layer_contrast_mix.wav")

        with col_sub:
            st.header("ğŸ“Š MIDI-Style Timeline")
            time_axis = np.linspace(0, duration, total_frames)
            fig = go.Figure()
            colors = ['#00d1ff', '#ff4b4b', '#7752fe', '#00ff88']
            for i in range(4):
                if any(f"Layer {i+1}" in n for n in active_layers):
                    fig.add_trace(go.Scatter(x=time_axis, y=vis_pitch[i], name=f"L{i+1}", line=dict(color=colors[i])))
            fig.update_layout(template="plotly_dark", height=400, xaxis=dict(rangeslider=dict(visible=True)))
            st.plotly_chart(fig, use_container_width=True)

    except Exception as e:
        st.error(f"ì˜¤ë¥˜: {e}")
