import streamlit as st
import cv2
import numpy as np
import io
import wave
import plotly.graph_objects as go

st.set_page_config(layout="wide", page_title="Professional Optical DAW")
st.title("ğŸ¹ Studio Grade: Optical Electronic DAW")

# --- ê³ ê¸‰ ì‚¬ìš´ë“œ í•©ì„± ì—”ì§„ ---
def generate_pro_sound(t, freq, layer_idx, sample_rate):
    """
    Layer 0: Deep Sub Bass - ë¬µì§í•œ ì €ìŒ (Sine + Harmonic)
    Layer 1: Warm Pluck - ë”°ëœ»í•˜ê²Œ ëŠê¸°ëŠ” ë¦¬ë“¬ (Filtered Square)
    Layer 2: Dreamy Lead - ë¶€ë“œëŸ¬ìš´ ë©œë¡œë”” (Filtered Saw)
    Layer 3: Top Chirp - ì„¬ì„¸í•œ ê³ ìŒ ì§ˆê° (Pure Sine High)
    """
    if layer_idx == 0:  # ğŸ¸ Deep Sub Bass
        # ì£¼íŒŒìˆ˜ë¥¼ ë‚®ì¶”ê³ (Base 40-80Hz), ë°°ìŒì„ ì„ì–´ ë¬µì§í•˜ê²Œ
        base_freq = freq * 0.5 
        wave = np.sin(2 * np.pi * base_freq * t) + 0.3 * np.sin(2 * np.pi * base_freq * 2 * t)
        env = np.ones(len(t)) # ë² ì´ìŠ¤ëŠ” ì§€ì†ì„± ìˆê²Œ
        return (wave * env * 0.8).astype(np.float32)

    elif layer_idx == 1:  # ğŸ¹ Warm Pluck
        # ì‚¬ê°íŒŒë¥¼ ì“°ë˜ ê³ ìŒì˜ ë‚ ì¹´ë¡œì›€ì„ ì–µì œí•˜ê¸° ìœ„í•´ ì‚¬ì¸íŒŒì™€ í˜¼í•©
        wave = 0.7 * np.sin(2 * np.pi * freq * t) + 0.3 * np.sign(np.sin(2 * np.pi * freq * t))
        # ì§€ìˆ˜ì  ê°ì‡  (Pluck)
        env = np.exp(-np.linspace(0, 8, len(t))) 
        return (wave * env * 0.6).astype(np.float32)

    elif layer_idx == 2:  # ğŸ¤ Dreamy Lead
        # í†±ë‹ˆíŒŒë¥¼ ì“°ë˜, ê³ ì—­ëŒ€ë¥¼ ë¶€ë“œëŸ½ê²Œ ì²˜ë¦¬
        wave = 0.5 * (2 * (t * freq - np.floor(0.5 + t * freq))) + 0.5 * np.sin(2 * np.pi * freq * t)
        # ì†Œë¦¬ê°€ ì„œì„œíˆ ì»¤ì¡Œë‹¤ê°€ ì‘ì•„ì§ (Soft Attack)
        env = np.sin(np.linspace(0, np.pi, len(t))) 
        return (wave * env * 0.4).astype(np.float32)

    else:  # âœ¨ Top Chirp
        # ë§¤ìš° ë†’ì€ ì£¼íŒŒìˆ˜ì—ì„œ ì°°ë‚˜ì˜ ì†Œë¦¬
        wave = np.sin(2 * np.pi * freq * 3 * t)
        env = np.zeros(len(t))
        env[:int(len(t)*0.2)] = np.linspace(1, 0, int(len(t)*0.2))
        return (wave * env * 0.3).astype(np.float32)

with st.sidebar:
    st.header("ğŸ› Studio Mixer")
    uploaded_file = st.file_uploader("ì˜ìƒì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=['mp4', 'mov', 'avi'])
    st.divider()
    active_layers = st.multiselect(
        "ğŸ”Š ë ˆì´ì–´ í™œì„±í™”",
        ["Layer 1 (Sub Bass)", "Layer 2 (Warm Pluck)", "Layer 3 (Soft Lead)", "Layer 4 (High Texture)"],
        default=["Layer 1 (Sub Bass)", "Layer 2 (Warm Pluck)", "Layer 3 (Soft Lead)", "Layer 4 (High Texture)"]
    )
    intensity_val = st.slider("ê´‘ì› ê°ë„", 30, 255, 180)
    master_gain = st.slider("Master Output", 0.5, 5.0, 2.0)

if uploaded_file:
    try:
        with open("temp_video.mp4", "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        cap = cv2.VideoCapture("temp_video.mp4")
        fps = cap.get(cv2.CAP_PROP_FPS) or 30
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        sample_rate = 22050 
        duration = total_frames / fps
        
        tracks_l = [np.zeros(int(sample_rate * duration) + sample_rate) for _ in range(4)]
        tracks_r = [np.zeros(int(sample_rate * duration) + sample_rate) for _ in range(4)]
        
        prog = st.progress(0)
        for i in range(total_frames):
            ret, frame = cap.read()
            if not ret: break
            
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            _, thresh = cv2.threshold(gray, intensity_val, 255, cv2.THRESH_BINARY)
            contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            start_idx = int(i * (sample_rate / fps))
            t = np.linspace(0, 1/fps, int(sample_rate/fps), False).astype(np.float32)
            
            sorted_cnts = sorted(contours, key=cv2.contourArea, reverse=True)[:4]
            
            for idx, cnt in enumerate(sorted_cnts):
                area = cv2.contourArea(cnt)
                M = cv2.moments(cnt)
                if M["m00"] == 0: continue
                cx = int(M["m10"]/M["m00"])
                
                # ì£¼íŒŒìˆ˜ ë§¤í•‘ ìµœì í™” (ë² ì´ìŠ¤ ë ˆì´ì–´ëŠ” ë‚®ê²Œ, ë¦¬ë“œëŠ” ë†’ê²Œ)
                base_f = [60, 150, 400, 1200][idx]
                freq = base_f + (area % 200)
                
                tone = generate_pro_sound(t, freq, idx, sample_rate)
                
                # ìŠ¤í…Œë ˆì˜¤ íŒ¬ë‹ ìµœì í™”
                pan_r = np.clip(cx / frame.shape[1], 0.1, 0.9)
                pan_l = 1.0 - pan_r
                
                end_idx = start_idx + len(tone)
                if end_idx < len(tracks_l[0]):
                    tracks_l[idx][start_idx:end_idx] += tone * pan_l * master_gain
                    tracks_r[idx][start_idx:end_idx] += tone * pan_r * master_gain

            if i % 30 == 0: prog.progress(i / total_frames)

        # ë¯¹ì‹±
        final_l, final_r = np.zeros_like(tracks_l[0]), np.zeros_like(tracks_r[0])
        for idx, name in enumerate(["Layer 1 (Sub Bass)", "Layer 2 (Warm Pluck)", "Layer 3 (Soft Lead)", "Layer 4 (High Texture)"]):
            if name in active_layers:
                final_l += tracks_l[idx]
                final_r += tracks_r[idx]

        # ë§ˆìŠ¤í„°ë§ (Soft Clipping)
        master_stereo = np.vstack((final_l, final_r)).T
        peak = np.max(np.abs(master_stereo))
        if peak > 0: master_stereo = (master_stereo / peak) * 0.85
        audio_int16 = (master_stereo * 32767).astype(np.int16)

        wav_buf = io.BytesIO()
        with wave.open(wav_buf, 'wb') as wf:
            wf.setnchannels(2); wf.setsampwidth(2); wf.setframerate(sample_rate); wf.writeframes(audio_int16.tobytes())

        # UI
        st.header("ğŸ§ Master Mix Playback")
        st.video(uploaded_file)
        st.audio(wav_buf.getvalue())
        st.download_button("ğŸ’¾ Studio Mix ë‹¤ìš´ë¡œë“œ", wav_buf.getvalue(), "studio_mix.wav")

    except Exception as e:
        st.error(f"ì˜¤ë¥˜: {e}")
