import streamlit as st
import cv2
import numpy as np
from scipy.io import wavfile
import io
import plotly.graph_objects as go

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(layout="wide", page_title="GarageLight DAW")
st.title("ğŸ¹ GarageLight: Optical DAW (Multi-Track Mode)")

# --- 1. ì‚¬ì´ë“œë°” ì»¨íŠ¸ë¡¤ ---
with st.sidebar:
    st.header("ğŸ› Control Panel")
    uploaded_file = st.file_uploader("ì˜ìƒì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=['mp4', 'mov', 'avi'])
    st.info("ê´‘ì›ë³„ë¡œ ìƒì„±ëœ íŠ¸ë™ì„ ì„ íƒí•˜ì—¬ ì¡°í•©í•˜ê³  ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”.")

if uploaded_file:
    try:
        # ì˜ìƒ ì²˜ë¦¬ ì„¤ì • (Full Frame)
        with open("temp_video.mp4", "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        cap = cv2.VideoCapture("temp_video.mp4")
        fps = cap.get(cv2.CAP_PROP_FPS) or 30
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        sample_rate = 22050 # ì²˜ë¦¬ ì†ë„ì™€ ì•ˆì •ì„±ì„ ìœ„í•´ ì¡°ì •
        max_tracks = 8 # ì‹œê°ì  í¸ì˜ë¥¼ ìœ„í•´ 8ê°œ íŠ¸ë™ìœ¼ë¡œ ì„¤ì •
        tracks_audio = [[] for _ in range(max_tracks)]
        tracks_visual = [[] for _ in range(max_tracks)]
        
        status_text = st.empty()
        status_text.write(f"ğŸš€ {total_frames}í”„ë ˆì„ ë¶„ì„ ë° ì‚¬ìš´ë“œ í•©ì„± ì¤‘...")
        prog = st.progress(0)

        # ë¶„ì„ ë£¨í”„
        for i in range(total_frames):
            ret, frame = cap.read()
            if not ret: break
            
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            _, thresh = cv2.threshold(gray, 230, 255, cv2.THRESH_BINARY)
            contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            duration = 1.0 / fps
            t = np.linspace(0, duration, int(sample_rate * duration), False)
            sorted_contours = sorted(contours, key=cv2.contourArea, reverse=True)[:max_tracks]
            
            for idx, cnt in enumerate(sorted_contours):
                area = cv2.contourArea(cnt)
                M = cv2.moments(cnt)
                if M["m00"] == 0: continue
                cx, cy = int(M["m10"] / M["m00"]), int(M["m01"] / M["m00"])
                
                # ë†’ì´ì— ë”°ë¥¸ ìŒì • + ì „ììŒ(Square wave)
                freq = 150 + ((frame.shape[0] - cy) * 1.5)
                vol = min(area / 1500, 0.7)
                tone = vol * np.sign(np.sin(2 * np.pi * freq * t)) # Square Wave
                
                tracks_audio[idx].append(tone)
                tracks_visual[idx].append(vol)
            
            # ë¹ˆ íŠ¸ë™ ì±„ìš°ê¸°
            for j in range(len(sorted_contours), max_tracks):
                tracks_audio[j].append(np.zeros_like(t))
                tracks_visual[j].append(0)
            
            if i % 20 == 0: prog.progress(i / total_frames)
        
        prog.empty()
        status_text.success("âœ… ì˜¤ì¼€ìŠ¤íŠ¸ë¼ ë ˆì´ì–´ ìƒì„± ì™„ë£Œ!")

        # UI ë ˆì´ì•„ì›ƒ
        col_vid, col_daw = st.columns([1, 2])
        
        with col_vid:
            st.header("ğŸ“½ Input Video")
            st.video(uploaded_file)

        with col_daw:
            st.header("ğŸ¹ Timeline & Mixer")
            
            # --- íŠ¸ë™ ì„ íƒ ê¸°ëŠ¥ ---
            available_tracks = [f"Track {i+1}" for i in range(max_tracks) if any(tracks_visual[i])]
            
            col_sel1, col_sel2 = st.columns([3, 1])
            with col_sel1:
                selected_tracks = st.multiselect("ì¡°í•©í•  ì•…ê¸°(íŠ¸ë™)ë¥¼ ì„ íƒí•˜ì„¸ìš”:", available_tracks, default=available_tracks)
            with col_sel2:
                if st.button("ì „ì²´ ì„ íƒ/í•´ì œ"):
                    selected_tracks = available_tracks

            # ì„ íƒëœ íŠ¸ë™ë“¤ í•©ì¹˜ê¸°
            mixed_audio = None
            if selected_tracks:
                for t_name in selected_tracks:
                    idx = int(t_name.split()[1]) - 1
                    track_data = np.concatenate(tracks_audio[idx])
                    if mixed_audio is None:
                        mixed_audio = track_data
                    else:
                        # ê¸¸ì´ ë§ì¶”ê¸° ë° ë¯¹ì‹±
                        min_len = min(len(mixed_audio), len(track_data))
                        mixed_audio = mixed_audio[:min_len] + track_data[:min_len]

            # --- ë§ˆìŠ¤í„° ì¶œë ¥ë¶€ ---
            if mixed_audio is not None:
                st.subheader("ğŸš Master Output (Selected Tracks Mixed)")
                # í”¼í¬ ë°©ì§€ (ë…¸ë©€ë¼ì´ì§•)
                mixed_audio = mixed_audio / np.max(np.abs(mixed_audio)) * 0.8
                st.audio(mixed_audio, sample_rate=sample_rate)
                
                buf = io.BytesIO()
                wavfile.write(buf, sample_rate, (mixed_audio * 32767).astype(np.int16))
                st.download_button(f"â¬‡ï¸ ì„ íƒí•œ {len(selected_tracks)}ê°œ ì•…ê¸° ì¡°í•© ë‹¤ìš´ë¡œë“œ (WAV)", buf.getvalue(), "mixed_lights.wav")

            st.divider()

            # --- ê°œë³„ íŠ¸ë™ íƒ€ì„ë¼ì¸ ---
            for i, name in enumerate(available_tracks):
                idx = int(name.split()[1]) - 1
                with st.expander(f"ğŸµ {name} Details", expanded=True):
                    fig = go.Figure()
                    fig.add_trace(go.Scatter(y=tracks_visual[idx], fill='tozeroy', line_color='#00d1ff'))
                    fig.update_layout(height=100, margin=dict(l=0, r=0, t=0, b=0), xaxis_visible=False, yaxis_visible=False)
                    st.plotly_chart(fig, use_container_width=True)

    except Exception as e:
        st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
