import streamlit as st
import cv2
import numpy as np
import io
import wave
import plotly.graph_objects as go

st.set_page_config(layout="wide", page_title="Optical Physics DAW")
st.title("ğŸ”¦ Optical Physics Synth: Light-to-Sound Mapping")

# --- ë¬¼ë¦¬ ê¸°ë°˜ ë§¤í•‘ ì—”ì§„ ---
def generate_phys_tone(t, freq, area, color_temp, intensity, sample_rate):
    """
    area (ë©´ì ) -> Bass/Sub ì„±ë¶„ ê²°ì •
    color_temp (ìƒ‰ì˜¨ë„/ìƒ‰ìƒ) -> ê¸°ë³¸ ì£¼íŒŒìˆ˜ ë° ë°°ìŒ êµ¬ì¡°
    intensity (ì„¸ê¸°/ë°ê¸°) -> Cutoff Filter (ì†Œë¦¬ì˜ ì„ ëª…ë„)
    """
    # 1. ë©´ì ì— ë”°ë¥¸ ë¬´ê²Œê° (ë©´ì ì´ í´ìˆ˜ë¡ ì„œë¸Œ í•˜ëª¨ë‹‰ìŠ¤ ì¶”ê°€)
    base_wave = np.sin(2 * np.pi * freq * t)
    if area > 1000:
        base_wave += 0.5 * np.sin(2 * np.pi * (freq/2) * t)
    
    # 2. ìƒ‰ì˜¨ë„ ê¸°ë°˜ ë°°ìŒ (ì°¨ê°€ìš´ ìƒ‰ì¼ìˆ˜ë¡ ë‚ ì¹´ë¡œìš´ ì‚¬ê°íŒŒ í˜¼í•©)
    # color_temp: 0(ë”°ëœ»í•¨/ì ìƒ‰) ~ 180(ì°¨ê°€ì›€/ì²­ìƒ‰)
    overtone_ratio = color_temp / 180.0
    wave_shape = (1 - overtone_ratio) * base_wave + overtone_ratio * np.sign(base_wave)
    
    # 3. ì„¸ê¸°(Intensity) ê¸°ë°˜ í•„í„°ë§ íš¨ê³¼
    # ë°ê¸°ê°€ ë‚®ìœ¼ë©´ ê³ ì£¼íŒŒë¥¼ ê¹ê³ , ë°ìœ¼ë©´ ë‚ ì¹´ë¡­ê²Œ (Low-pass effect)
    cutoff = max(0.1, intensity / 255.0)
    wave_shape = wave_shape * cutoff
    
    return wave_shape.astype(np.float32)

def apply_sustain(tone, sample_rate, persistence):
    """
    persistence (ì§€ì†ì„±) -> Reverb/Release ê²°ì •
    """
    n = len(tone)
    # ì§€ì†ì„±ì´ ë†’ì„ìˆ˜ë¡ í…Œì¼(Tail)ì´ ê¸´ ì—”ë²¨ë¡œí”„ ì ìš©
    release_time = min(0.1 + (persistence * 0.4), 0.5) 
    release_samples = int(sample_rate * release_time)
    
    if n > release_samples:
        env = np.ones(n)
        env[-release_samples:] = np.linspace(1, 0, release_samples)
        return tone * env
    return tone

with st.sidebar:
    st.header("ğŸ”¬ Physics Analysis")
    uploaded_file = st.file_uploader("ì˜ìƒì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=['mp4', 'mov', 'avi'])
    st.divider()
    threshold_val = st.slider("ê´‘ì› ì¸ì‹ ë¬¸í„±ê°’ (Intensity)", 50, 255, 200)
    min_area = st.number_input("ìµœì†Œ ê°ì§€ ë©´ì  (Area)", 10, 1000, 100)
    master_vol = st.slider("Master Gain", 0.1, 5.0, 1.5)

if uploaded_file:
    try:
        with open("temp_video.mp4", "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        cap = cv2.VideoCapture("temp_video.mp4")
        fps = cap.get(cv2.CAP_PROP_FPS) or 30
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        sample_rate = 22050 
        
        # 4ì±„ë„ ë ˆì´ì–´ (ë©´ì ìˆœ)
        tracks_l = [np.zeros(int(sample_rate * (total_frames/fps)) + sample_rate) for _ in range(4)]
        tracks_r = [np.zeros(int(sample_rate * (total_frames/fps)) + sample_rate) for _ in range(4)]
        
        # ë°ì´í„° ì‹œê°í™”ìš©
        vis_intensity = [[] for _ in range(4)]
        
        prog = st.progress(0)
        for i in range(total_frames):
            ret, frame = cap.read()
            if not ret: break
            
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
            _, thresh = cv2.threshold(gray, threshold_val, 255, cv2.THRESH_BINARY)
            contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            start_idx = int(i * (sample_rate / fps))
            t = np.linspace(0, 1/fps, int(sample_rate/fps), False).astype(np.float32)
            
            # ê´‘ì›ì„ ë©´ì ìˆœìœ¼ë¡œ 4ê°œ ë¶„ì„
            sorted_cnts = sorted(contours, key=cv2.contourArea, reverse=True)[:4]
            
            for idx, cnt in enumerate(sorted_cnts):
                area = cv2.contourArea(cnt)
                if area < min_area: continue
                
                # 1. ìƒ‰ìƒ(Hue) -> ìƒ‰ì˜¨ë„ ëŒ€ìš©
                mask = np.zeros(gray.shape, np.uint8)
                cv2.drawContours(mask, [cnt], -1, 255, -1)
                avg_hsv = cv2.mean(hsv, mask=mask)
                color_temp = avg_hsv[0] # Hueê°’
                
                # 2. ì„¸ê¸°(Intensity)
                intensity = cv2.mean(gray, mask=mask)[0]
                
                # 3. ì§€ì†ì„± (ë‹¨ìˆœ í”„ë ˆì„ ë¶„ì„ ëŒ€ì‹  ë©´ì  ê°€ì¤‘ì¹˜ í™œìš©)
                persistence = area / 5000.0
                
                # ì£¼íŒŒìˆ˜ ë§¤í•‘ (ìƒ‰ì˜¨ë„ì™€ ë©´ì  ì¡°í•©)
                freq = 100 + (color_temp * 2) + (10000 / (area + 1))
                
                # ì‚¬ìš´ë“œ ìƒì„±
                tone = generate_phys_tone(t, freq, area, color_temp, intensity, sample_rate)
                tone = apply_sustain(tone, sample_rate, persistence)
                
                # ìœ„ì¹˜ ê¸°ë°˜ íŒ¬ë‹
                M = cv2.moments(cnt)
                cx = int(M["m10"]/M["m00"]) if M["m00"] != 0 else frame.shape[1]//2
                pan_r = cx / frame.shape[1]
                pan_l = 1.0 - pan_r
                
                end_idx = start_idx + len(tone)
                if end_idx < len(tracks_l[0]):
                    tracks_l[idx][start_idx:end_idx] += tone * pan_l * master_vol
                    tracks_r[idx][start_idx:end_idx] += tone * pan_r * master_vol
                vis_intensity[idx].append(intensity)

            for j in range(len(sorted_cnts), 4): vis_intensity[j].append(0)
            if i % 30 == 0: prog.progress(i / total_frames)

        # ë¯¹ì‹± ë° ë§ˆìŠ¤í„°ë§
        master_l = np.clip(np.sum(tracks_l, axis=0), -1, 1)
        master_r = np.clip(np.sum(tracks_r, axis=0), -1, 1)
        master_stereo = np.vstack((master_l, master_r)).T
        audio_int16 = (master_stereo * 32767).astype(np.int16)

        wav_buf = io.BytesIO()
        with wave.open(wav_buf, 'wb') as wf:
            wf.setnchannels(2); wf.setsampwidth(2); wf.setframerate(sample_rate); wf.writeframes(audio_int16.tobytes())

        col1, col2 = st.columns([1.5, 1])
        with col1:
            st.header("ğŸ“½ Optical Sync Analysis")
            st.video(uploaded_file)
            st.audio(wav_buf.getvalue())
            
            st.subheader("Layer Mixer (Monitoring)")
            for i in range(4):
                col_btn, col_info = st.columns([1, 2])
                with col_btn:
                    # ê°œë³„ íŠ¸ë™ ì¶”ì¶œ ê¸°ëŠ¥ ìœ ì§€
                    t_buf = io.BytesIO()
                    t_data = np.vstack((tracks_l[i], tracks_r[i])).T
                    t_int16 = (np.clip(t_data, -1, 1) * 32767).astype(np.int16)
                    with wave.open(t_buf, 'wb') as wf:
                        wf.setnchannels(2); wf.setsampwidth(2); wf.setframerate(sample_rate); wf.writeframes(t_int16.tobytes())
                    st.download_button(f"ğŸ“¥ Layer {i+1} WAV", t_buf.getvalue(), f"layer_{i+1}.wav")
                with col_info:
                    st.caption(f"Track {i+1}: Intensity-driven Resonance")

        with col2:
            st.header("ğŸ“Š Physical Data")
            time_axis = np.linspace(0, total_frames/fps, total_frames)
            fig = go.Figure()
            for i in range(4):
                fig.add_trace(go.Scatter(x=time_axis, y=vis_intensity[i], name=f"L{i+1} Intensity", fill='tozeroy'))
            fig.update_layout(template="plotly_dark", height=400, xaxis_title="Time", yaxis_title="Intensity (0-255)")
            st.plotly_chart(fig, use_container_width=True)

    except Exception as e:
        st.error(f"ë¶„ì„ ì‹¤íŒ¨: {e}")
